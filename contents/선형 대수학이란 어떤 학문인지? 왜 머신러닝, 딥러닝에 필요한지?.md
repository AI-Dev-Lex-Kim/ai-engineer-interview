# 선형대수학이란 어떤 학문인지? 왜 머신러닝/딥러닝에 필요한지?

<mark>**어떤 학문인지?**</mark>

<mark><mark>**직선적인 관계를 다루는 수학의 한 분야**</mark></mark> 선형대수학은 이다.
더 자세히 설명하면, <mark>**벡터와 벡터사이의 직선으로 변환**</mark>을 연구하는 학문이다.

<br>

벡터란 <mark><mark>**방향과 크기를 모두 가지고 있는 값**</mark></mark>이다.

예를 들어 `(3, 4)`라는 값은 원점인 `(0, 0)`에서 `(3, 4)`까지를 잇는 화살표로 생각할 수 있어 방향과 크기를 모두 가지므로 벡터라고 할 수 있다.

<br>

벡터들이 모여있는 공간에서 <mark><mark>**스칼라를 통해 변환이 가능**</mark></mark>하다.

스칼라란 크기만을 가지고 방향이 없는 단순한 숫자이다.

벡터와 스칼라의 연산을 통해 <mark><mark>**벡터 공간에서 다양한 변환**</mark></mark>이 일어난다. 이것을 <mark><mark>**선형 변환**</mark></mark>이라고 한다.

<br>

선형변환은 단지 스칼라로만으로 가능한 것이 아니라 행렬로도 가능하다.

행렬이란 숫자들을 직사각형 모양으로 배열한것이다.

행렬을 벡터에 곱함으로써 벡터의 크기와 방향을 바꾸는 선형 변환을 <mark><mark>**여러번 수행할 수 있다.**</mark></mark>

<br>

<mark>왜 머신러닝/딥러닝에 필요한지?</mark>

딥러닝 모델이 데이터를 처리하고 학습하는 과정 자체가 이러한 선형대수학의 개념들로 이루어져있다.

<mark><mark>**데이터들은 대부분 행렬의 형태로 표현**</mark></mark>된다.

<br>

모델의 입력으로 행렬 형태의 데이터가 들어간다.

이 입력 데이터는 모델 내부의 여러 <mark><mark>**레이어를 통과하며, 행렬과 벡터의 곱셈 연산**</mark></mark>을 거치게 된다.

예를 들어 이전 계층의 출력인 벡터에 가중치 행렬을 곱하고 편향 벡터를 더하는 연산을 수행할 수 있다.

<br>

행렬 곱셈 연산은 <mark><mark>**병렬 처리에 매우 효과적**</mark></mark>이다.

GPU를 통해 빠르게 계산할 수 있고, 이것이 딥러닝 모델이 <mark><mark>**대규모 데이터를 빠르게 학습할 수 있는 이유**</mark></mark>이다.

<br>

딥러닝 모델에서 <mark><mark>**출력 역시 행렬 또는 벡터 형태**</mark></mark>로 나온다.

분류(classification) 모델의 경우 마지막 게층의 출력은 보통 벡터 형태로 나온다.

예를 들어 특정 클래스에 속할 확률 (클래스 수, 1) 형태를 가진다. 회귀 문제는 (1, 1) 형태를 가진다.

<br>

<mark><mark>**손실 함수**</mark></mark> 역시 선형대수학의 개념을 이용해 정의된다.

이 손실을 최소화하는 방향으로 모델의 가중치와 편향을 업데이트하는 최적화 과정인 경사하강법 역시 <mark><mark>**행렬과 벡터의 미분을 이용해 계산**</mark></mark>한다.

<br>

따라서 선형대수학은 단순히 행렬과 벡터로 표현하는것을 넘어서, 모델의 내부 연산, 예측 결과 해석, 모델 학습 시키는 최적화 과정까지 <mark><mark>**딥러닝의 모든 핵심적인 부분에 깊숙이 관여**</mark></mark>한다.

딥러닝을 제대로 이해하고 활용하기 위해서는 <mark><mark>**선형대수학에 대해 깊은 이해가 필수적**</mark></mark>이라고 할 수 있다.

<br>
